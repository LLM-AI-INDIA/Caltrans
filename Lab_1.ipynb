{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 1"
      ],
      "metadata": {
        "id": "suGClHhoh3Bx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement: Accessing and interacting with the LLMs"
      ],
      "metadata": {
        "id": "VQaDt7MaG5RO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGUWD_WoQZHp",
        "outputId": "bbcd4dff-4a80-4b16-8c89-155fefb31f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.46.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, os, getpass, csv\n",
        "from typing import Dict, Any, Callable"
      ],
      "metadata": {
        "id": "cqr18ku4iBbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the secret keys"
      ],
      "metadata": {
        "id": "MRWckKQEh6Wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. load the file --------------------------------------------------------\n",
        "keys = {}\n",
        "with open(\"keys.csv\") as f:\n",
        "    for line in f:\n",
        "        if line.strip():                     # skip blank lines\n",
        "            k, v = line.strip().split(\",\", 1)\n",
        "            keys[k] = v\n",
        "\n",
        "# --- 2. export to environment ------------------------------------------------\n",
        "for k in (\"OPENAI_API_KEY\", \"GEMINI_API_KEY\"):\n",
        "    os.environ[k] = keys[k]\n",
        "\n",
        "print(\"Keys imported and exported to environment.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CE540BRQknU",
        "outputId": "80423ca3-fd58-4655-f504-180aaadb8b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys imported and exported to environment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the query response functions for OpenAI and Gemini Models, followed by function to compare the responses"
      ],
      "metadata": {
        "id": "J5stc_tviGrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SDK imports\n",
        "import openai\n",
        "try:\n",
        "    from google import genai\n",
        "except Exception as e:\n",
        "    genai = None\n",
        "\n",
        "# Read API keys from environment variables (set in Step 2)\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "gemini_api_key = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
        "\n",
        "prompt = \"Explain the difference between Machine Learning and Generative AI in simple terms.\"\n",
        "\n",
        "# --- Function Definitions for Real API Calls using SDKs ---\n",
        "\n",
        "def query_openai(prompt, api_key):\n",
        "    \"\"\"Queries OpenAI using the official SDK.\"\"\"\n",
        "    try:\n",
        "        # Modern OpenAI client style\n",
        "        try:\n",
        "            client = openai.OpenAI(api_key=api_key)\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content.strip()\n",
        "        except Exception:\n",
        "            # Fallback legacy style\n",
        "            openai.api_key = api_key\n",
        "            resp = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return resp.choices[0].message['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"OpenAI Error: {type(e).__name__} - {e}\"\n",
        "\n",
        "def query_gemini(prompt, api_key):\n",
        "    \"\"\"Queries Gemini using google-genai SDK, if available.\"\"\"\n",
        "    if genai is None:\n",
        "        return \"Gemini Error: google-genai SDK not installed or import failed.\"\n",
        "    try:\n",
        "        client = genai.Client(api_key=api_key)\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=prompt,\n",
        "            config={\"max_output_tokens\": 150}\n",
        "        )\n",
        "        text = getattr(response, \"text\", None) or getattr(response, \"outputs\", None)\n",
        "        if isinstance(text, str):\n",
        "            return text.strip()\n",
        "        if isinstance(text, list) and len(text) > 0:\n",
        "            return str(text[0]).strip()\n",
        "        return str(response).strip()\n",
        "    except Exception as e:\n",
        "        return f\"Gemini Error: {type(e).__name__} - {e}\"\n",
        "\n",
        "# --- Comparison Function (MINIMAL OUTPUT) ---\n",
        "\n",
        "def compare_responses():\n",
        "    \"\"\"Fetches real responses, measures latency, and prints only length and latency.\"\"\"\n",
        "\n",
        "    models: Dict[str, Callable] = {\n",
        "        \"OpenAI\": lambda p: query_openai(p, openai_api_key),\n",
        "        \"Gemini\": lambda p: query_gemini(p, gemini_api_key)\n",
        "    }\n",
        "\n",
        "    results: Dict[str, Any] = {}\n",
        "\n",
        "    print(\"--- Fetching Responses (Using SDKs & Your API Keys) ---\")\n",
        "    for model_name, query_func in models.items():\n",
        "        start_time = time.time()\n",
        "        response_text = query_func(prompt).strip()\n",
        "        latency = time.time() - start_time\n",
        "\n",
        "        results[model_name] = {\n",
        "            \"latency\": latency,\n",
        "            \"char_length\": len(response_text)\n",
        "        }\n",
        "        print(f\"Finished fetching response for {model_name}...\")\n",
        "\n",
        "    # Print the final Comparison Table\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\" LLM Length and Latency Comparison \")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for model_name, data in results.items():\n",
        "        print(f\"\\n--- {model_name} ---\")\n",
        "        print(f\"Latency: {data['latency']:.4f}s\")\n",
        "        print(f\"Character Length: {data['char_length']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Run comparison\n",
        "if __name__ == \"__main__\":\n",
        "    compare_responses()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPlyKJV1Qun8",
        "outputId": "e3f54bcd-a833-4056-f64b-937f1ca05abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fetching Responses (Using SDKs & Your API Keys) ---\n",
            "Finished fetching response for OpenAI...\n",
            "Finished fetching response for Gemini...\n",
            "\n",
            "==================================================\n",
            " LLM Length and Latency Comparison \n",
            "==================================================\n",
            "\n",
            "--- OpenAI ---\n",
            "Latency: 2.4734s\n",
            "Character Length: 759\n",
            "\n",
            "--- Gemini ---\n",
            "Latency: 1.9105s\n",
            "Character Length: 610\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mVkMEPPsHdD_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}