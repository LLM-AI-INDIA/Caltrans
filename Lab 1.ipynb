{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGUWD_WoQZHp",
        "outputId": "bb025679-ea75-49b5-ab45-8fc68dc97797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.45.0)\n",
            "Collecting groq\n",
            "  Downloading groq-0.33.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Downloading groq-0.33.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.33.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai google-genai groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "# Prompt for keys (they will not be shown). Press Enter to leave blank (useful for testing error handling).\n",
        "openai_api_key = getpass.getpass(\"OpenAI API Key (press Enter to skip): \")\n",
        "gemini_api_key = getpass.getpass(\"Gemini API Key (press Enter to skip): \")\n",
        "groq_api_key = getpass.getpass(\"Groq API Key (press Enter to skip): \")\n",
        "\n",
        "# Store them in env for use by the script below\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "os.environ['GEMINI_API_KEY'] = gemini_api_key\n",
        "os.environ['GROQ_API_KEY'] = groq_api_key\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CE540BRQknU",
        "outputId": "243e1e0e-b184-4b90-dd1b-ab4c2bbdecba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key (press Enter to skip): ··········\n",
            "Gemini API Key (press Enter to skip): ··········\n",
            "Groq API Key (press Enter to skip): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from typing import Dict, Any, Callable\n",
        "import os\n",
        "\n",
        "# SDK imports\n",
        "import openai\n",
        "try:\n",
        "    from google import genai\n",
        "except Exception as e:\n",
        "    genai = None\n",
        "try:\n",
        "    from groq import Groq\n",
        "except Exception as e:\n",
        "    Groq = None\n",
        "\n",
        "# Read API keys from environment variables (set in Step 2)\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "gemini_api_key = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\", \"\")\n",
        "\n",
        "prompt = \"Explain the difference between Machine Learning and Generative AI in simple terms.\"\n",
        "\n",
        "# --- Function Definitions for Real API Calls using SDKs ---\n",
        "\n",
        "def query_openai(prompt, api_key):\n",
        "    \"\"\"Queries OpenAI using the official SDK.\"\"\"\n",
        "    try:\n",
        "        # Modern OpenAI client style\n",
        "        try:\n",
        "            client = openai.OpenAI(api_key=api_key)\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content.strip()\n",
        "        except Exception:\n",
        "            # Fallback legacy style\n",
        "            openai.api_key = api_key\n",
        "            resp = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return resp.choices[0].message['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"OpenAI Error: {type(e).__name__} - {e}\"\n",
        "\n",
        "def query_gemini(prompt, api_key):\n",
        "    \"\"\"Queries Gemini using google-genai SDK, if available.\"\"\"\n",
        "    if genai is None:\n",
        "        return \"Gemini Error: google-genai SDK not installed or import failed.\"\n",
        "    try:\n",
        "        client = genai.Client(api_key=api_key)\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=prompt,\n",
        "            config={\"max_output_tokens\": 150}\n",
        "        )\n",
        "        text = getattr(response, \"text\", None) or getattr(response, \"outputs\", None)\n",
        "        if isinstance(text, str):\n",
        "            return text.strip()\n",
        "        if isinstance(text, list) and len(text) > 0:\n",
        "            return str(text[0]).strip()\n",
        "        return str(response).strip()\n",
        "    except Exception as e:\n",
        "        return f\"Gemini Error: {type(e).__name__} - {e}\"\n",
        "\n",
        "def query_groq(prompt, api_key):\n",
        "    \"\"\"Queries Groq using the Groq SDK if available.\"\"\"\n",
        "    if Groq is None:\n",
        "        return \"Groq Error: Groq SDK not installed or import failed.\"\n",
        "    try:\n",
        "        client = Groq(api_key=api_key)\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"mixtral-8x7b-32768\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=150,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Groq Error: {type(e).__name__} - {e}\"\n",
        "\n",
        "# --- Comparison Function (MINIMAL OUTPUT) ---\n",
        "\n",
        "def compare_responses():\n",
        "    \"\"\"Fetches real responses, measures latency, and prints only length and latency.\"\"\"\n",
        "\n",
        "    models: Dict[str, Callable] = {\n",
        "        \"OpenAI\": lambda p: query_openai(p, openai_api_key),\n",
        "        \"Gemini\": lambda p: query_gemini(p, gemini_api_key),\n",
        "        \"Groq\": lambda p: query_groq(p, groq_api_key),\n",
        "    }\n",
        "\n",
        "    results: Dict[str, Any] = {}\n",
        "\n",
        "    print(\"--- Fetching Responses (Using SDKs & Your API Keys) ---\")\n",
        "    for model_name, query_func in models.items():\n",
        "        start_time = time.time()\n",
        "        response_text = query_func(prompt).strip()\n",
        "        latency = time.time() - start_time\n",
        "\n",
        "        results[model_name] = {\n",
        "            \"latency\": latency,\n",
        "            \"char_length\": len(response_text)\n",
        "        }\n",
        "        print(f\"Finished fetching response for {model_name}...\")\n",
        "\n",
        "    # Print the final Comparison Table\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\" LLM Length and Latency Comparison \")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for model_name, data in results.items():\n",
        "        print(f\"\\n--- {model_name} ---\")\n",
        "        print(f\"Latency: {data['latency']:.4f}s\")\n",
        "        print(f\"Character Length: {data['char_length']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Run comparison\n",
        "if __name__ == \"__main__\":\n",
        "    compare_responses()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPlyKJV1Qun8",
        "outputId": "0c4d9f74-6272-41ae-fa94-fea6fd4f984e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fetching Responses (Using SDKs & Your API Keys) ---\n",
            "Finished fetching response for OpenAI...\n",
            "Finished fetching response for Gemini...\n",
            "Finished fetching response for Groq...\n",
            "\n",
            "==================================================\n",
            " LLM Length and Latency Comparison \n",
            "==================================================\n",
            "\n",
            "--- OpenAI ---\n",
            "Latency: 1.8169s\n",
            "Character Length: 561\n",
            "\n",
            "--- Gemini ---\n",
            "Latency: 2.2887s\n",
            "Character Length: 610\n",
            "\n",
            "--- Groq ---\n",
            "Latency: 0.2680s\n",
            "Character Length: 153\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}